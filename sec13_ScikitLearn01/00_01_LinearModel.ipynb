{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Modeling in Scikit-Learn\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#\n",
    "    \n",
    "We will disucssed the following methods for the Linear Model:\n",
    "\n",
    "1. Linear Regression\n",
    "2. Ridge Regression\n",
    "3. LASSO (Least Absolute Shrinkage and Selection Operator)\n",
    "4. Multi-task LASSO\n",
    "5. Elastic-Net\n",
    "6. Multi-Task Elastic-Net\n",
    "7. Bayesian Regression\n",
    "8. Logistic Regression\n",
    "9. Generalized Linear Regression\n",
    "10. SGD (Stochastic Gradient Descent)\n",
    "11. Polynomial Regression\n",
    "\n",
    "For Linear Model, in mathematical notation, if $\\hat{y}$ is the predicted value.\n",
    "\n",
    "$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n",
    "\n",
    "Where: \n",
    "$w = (w_1, ..., w_p)$ as coef_ and \n",
    "$w_0$ as intercept_.\n",
    "\n",
    "1. We can use Logistic Regression to perform classification with generalized linear models\n",
    "2. Others are regular regression with flaoting point results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/linear_model.html#\n",
    "    \n",
    "The following table lists out various linear models provided by Scikit-Learn:\n",
    "    \n",
    "| No  | Model and Description |\n",
    "| :-- | :-------------------- |\n",
    "| 1   | Linear Regression     |\n",
    "|     | It is one of the best statistical models that studies the relationship between a dependent variable (Y) with a given set of independent variables (X). |\n",
    "| 2   | Ridge Regression      |\n",
    "|     | Ridge Regression (or Tikhonov regularization) is the regularization technique that performs L2 regularization. It modifies the loss function by adding the penalty (shrinkage quantity) equivalent to the square of the magnitude of coefficients. |\n",
    "| 3   | LASSO |\n",
    "|     | LASSO is the regularization technique that performs L1 regularization. It modifies the loss function by adding the penalty (shrinkage quantity) equivalent to the summation of the absolute value of coefficients. |\n",
    "| 4   | Multi-Task LASSO |\n",
    "|     | It allows to fit multiple regression problems jointly enforcing the selected features to be same for all the regression problems, also called tasks. Scikit-learn provides a linear model named MultiTaskLasso, trained with a mixed L1, L2-norm for regularization, which estimates sparse coefficients for multiple regression problems jointly. |\n",
    "| 5   | Elastic-Net |\n",
    "|     | The Elastic-Net is a regularized regression method that linearly combines both penalties i.e. L1 and L2 of the Lasso and Ridge regression methods. It is useful when there are multiple correlated features. |\n",
    "| 6   | Multi-task Elastic-Net |\n",
    "|     | It is an Elastic-Net model that allows to fit multiple regression problems jointly enforcing the selected features to be same for all the regression problems, also called tasks. |\n",
    "| 7   | Bayesian Regression |\n",
    "|     | Bayesian regression allows a natural mechanism to survive insufficient data or poorly distributed data by formulating linear regression using probability distributors rather than point estimates. |\n",
    "| 8   | Logistic Regression   |\n",
    "|     | Logistic regression is a classification algorithm rather than regression algorithm. Based on a given set of independent variables, it is used to estimate discrete value (0 or 1, yes/no, true/false). |\n",
    "| 9   | Generalized Linear Regression   |\n",
    "|     | Generalized Linear Models (GLM) extend linear models in two ways. |\n",
    "|     | First, the predicted values $\\hat{y}$ are linked to a linear combination of the input variables $X$. |\n",
    "|     | Secondly, the squared loss function is replaced by the unit deviance $d$ of a distribution in the exponential family. |\n",
    "| 10  | SGD (Stochastic Gradient Descent) |\n",
    "|     | Stochastic gradient descent is a simple and very efficient approach to fit linear models. |\n",
    "| 11  | Polynomial Regression:  |\n",
    "|     | Extended linear models with basis functions. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by understanding what is linear regression in Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
